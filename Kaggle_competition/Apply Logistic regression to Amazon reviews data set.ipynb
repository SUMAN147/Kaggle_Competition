{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LoadinG The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DANAV\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 12)\n",
      "(200, 12)\n",
      "<bound method NDFrame.head of          index      Id   ProductId          UserId  \\\n",
      "9023    155416  168562  B0001ES9F8  A1R9HPMUY9DGVE   \n",
      "51      417904  451926  B00004CXX9  A31V5BH5YHG4TZ   \n",
      "3884    437963  473617  B0007V1Q7I  A2Q261K2VVCDHE   \n",
      "12264   356387  385494  B0002994Q0  A1YZ5CHHCLP8Y5   \n",
      "51113    65409   71054  B000F4D5JE  A2E3WMF9RWW2X2   \n",
      "31621   362365  391888  B000CQBZPG  A1AJ5JVIO3PD25   \n",
      "14367    76105   82818  B0002PHDYO  A1VPUK22B4MTDE   \n",
      "47456   254362  275779  B000EVLS2O  A2BKC69F4BRO29   \n",
      "43469    49112   53347  B000EMM9YY  A25HD1WPIAYPLQ   \n",
      "195209  489631  529434  B0029NIF44   AGJLD33CGEXXL   \n",
      "5582    218028  236346  B000CONM8Q  A10CMEPEV19WAB   \n",
      "223108  208660  226130  B0036X748E  A2NPF2TZWXX5RT   \n",
      "95646   401783  434432  B000P8ZNOK  A1NFYVLLYNX48R   \n",
      "164268   91411   99442  B001FA1KU8  A2CB7HX0U1CUKW   \n",
      "149578  408767  442095  B001EO5MZY   AV50PSPVKS3RD   \n",
      "19007   323302  349941  B0006J32A0  A18GY5MOJU8KK6   \n",
      "151852  184973  200653  B001EO5UVK  A11V0DGWZIRBHO   \n",
      "4013    373059  403432  B0008IUV12   ARUVT3IJQD579   \n",
      "14156   232607  252315  B000LKTEYC  A16KK3YHCWE29C   \n",
      "16905   189507  205500  B000Q555EK  A3QF6V8QNNTXPB   \n",
      "2848    166441  180473  B0002ZFPIU  A34VY5GQF9IMN9   \n",
      "33650    27675   30172  B000DZFMEQ  A2OPQHX0YICRFI   \n",
      "104401  170753  185250  B000UHDF28  A1SHX777NCRX1C   \n",
      "8210    448589  485038  B000EVG87Y  A1D05K2JMCK3KT   \n",
      "8768    153945  166921  B000F33X92  A1OYVHYFVQ8XAZ   \n",
      "54480   289193  313241  B000FD7C6M   A717XPBO4H466   \n",
      "98502   244192  264801  B000QV0GOI  A3PHO07DYWOVHN   \n",
      "115252  342282  370296  B000ZSZ5S4  A1VEOWIH3D0PTZ   \n",
      "14101   271720  294510  B000LBW62I   AGG5C32AETVZZ   \n",
      "142400  483672  522970  B001E5E08I  A1R9QOPV6HVEKF   \n",
      "...        ...     ...         ...             ...   \n",
      "40697   231100  250682  B000EEWZEQ   AXKXFB6C9Z9BH   \n",
      "41482   216097  234192  B003EMW4ZA  A2JC6UWL0LTLSE   \n",
      "31168   336233  363810  B001M08YZA   AWWFMWIGQVDHL   \n",
      "23770   158934  172314  B001B3JAL0   A9GIGJUB98JNR   \n",
      "31236   290525  314736  B001M0A6C4  A3OP6FTQB9LZSE   \n",
      "17340   394512  426610  B00061KZ1M  A1T90I8HWU6P66   \n",
      "44731    74838   81407  B003ZXFWZC  A2NHXWDKXWLCYE   \n",
      "36306   503413  544367  B002GWH5XK    AXNCSYS49FXA   \n",
      "45818   435780  471232  B00451UN84  A3RAHRVYFK1PC7   \n",
      "40519   182519  197963  B00384NZTI   A6S8J6UI2V1N0   \n",
      "246245   87508   95248  B00401OZ1U   AQ6IZFEZ142VF   \n",
      "292001   76659   83399  B005ZBZLT4   AMNBQZ975X2D6   \n",
      "24723   135972  147570  B001D0IZBM  A3AYPBB7Z3C1IA   \n",
      "40195   442395  478349  B00362FJD2  A2LWAV5B1QOBQB   \n",
      "35388   220490  239009  B002C4QLGE   ALKV9INFN78RC   \n",
      "1867    470670  508988  B0001N7RLQ  A3J0OEQ8Q28AO9   \n",
      "22314   457343  494502  B0016MHL6W  A26YO5A2Y8EBEG   \n",
      "36113   380298  411205  B002FZLJWG   ARX86ZNDJ69D3   \n",
      "52688   415599  449451  B005F97I2E  A2HS4VYRTLD8W2   \n",
      "296057   15754   17223  B006K02VJC  A25ZGO9ELMK0U2   \n",
      "46318   144066  156314  B00473XC9C   AHO4DUTLJADJC   \n",
      "204247   95729  104040  B002GWH8N2   AH5XD5UC3DP5C   \n",
      "247440  218071  236390  B00410RQSO  A1ASQ87A2S19LN   \n",
      "155503  392149  424051  B001EPPB9A   AZJG3TUN1IK1C   \n",
      "23452    54860   59538  B001A7RNB6  A18JWKLKEQG7VZ   \n",
      "204018  159718  173149  B002GWFAUU  A1MQW2P9D3HFRG   \n",
      "87573    75575   82238  B000M5XN1Q  A10LGDVFA8UMHQ   \n",
      "98096   488003  527698  B000QSON4K   A1YM74K0WA10O   \n",
      "242532  453467  490275  B003WO51JG  A1ZW0CLNFF1FSA   \n",
      "56400   506911  548142  B007RTR9G0  A1ODOGXEYECQQ8   \n",
      "\n",
      "                              ProfileName  HelpfulnessNumerator  \\\n",
      "9023                           B. Alvarez                     0   \n",
      "51         Kenny Loggins (not the singer)                     1   \n",
      "3884              lokeedone \"lokeed4life\"                     5   \n",
      "12264                             Numomee                     4   \n",
      "51113                           K. Duvall                     2   \n",
      "31621                      Joyce A. Brenc                     0   \n",
      "14367                   Thomas J. Stanley                    11   \n",
      "47456                         Kevin Meboe                     6   \n",
      "43469                         S. Peterson                     3   \n",
      "195209                               Hope                     3   \n",
      "5582                 John C. \"Programmer\"                     3   \n",
      "223108                        Doug Lawton                     7   \n",
      "95646       Pixina Snowmantle \"Pixie Meg\"                     1   \n",
      "164268                     Bobster Deluxe                     4   \n",
      "149578                              Baker                     0   \n",
      "19007                         Susanwillow                     0   \n",
      "151852                         A. Rawlins                     1   \n",
      "4013        Louis Esposito \"Lou Esposito\"                     6   \n",
      "14156                             QF Jane                     2   \n",
      "16905                    Sara Smith Joyce                     1   \n",
      "2848     Daniel J. Sauer \"USMCDesert Rat\"                     0   \n",
      "33650                       J. Desjardins                     0   \n",
      "104401                       Sicklefinger                     7   \n",
      "8210                            Dan Chase                     2   \n",
      "8768              Katrina Jensen \"leokat\"                     5   \n",
      "54480                            Sone Spl                     2   \n",
      "98502           JACK BUTLER \"Jack Butler\"                     0   \n",
      "115252  Robert W. Derrickson \"FUN SEEKER\"                     1   \n",
      "14101                               Snave                     1   \n",
      "142400                     Adam F. Jewell                     0   \n",
      "...                                   ...                   ...   \n",
      "40697                              JFMile                     0   \n",
      "41482                          FW Shopper                     0   \n",
      "31168                                Roxy                     2   \n",
      "23770            Chen Sun \"WebAndNet.com\"                     1   \n",
      "31236                          Alex G. M.                     2   \n",
      "17340                              KarenT                     0   \n",
      "44731                        Cereal_lover                     1   \n",
      "36306                     rapid butterfly                     0   \n",
      "45818                      Tiffany Santos                     1   \n",
      "40519                    J. G. Harrington                     0   \n",
      "246245                dianech \"diane9709\"                     0   \n",
      "292001                               MARY                     0   \n",
      "24723                              Amanda                     0   \n",
      "40195                  Speaker to Animals                     0   \n",
      "35388                         SANDY LEE B                     0   \n",
      "1867          Lisby \"lisby@earthlink.net\"                     0   \n",
      "22314                     IowaHawkeyesFan                     0   \n",
      "36113                           Preceptis                     0   \n",
      "52688                               maria                     0   \n",
      "296057                                Kim                     0   \n",
      "46318                             Linder7                     0   \n",
      "204247                            ccmoren                     0   \n",
      "247440                              JNMom                     0   \n",
      "155503                    Dorothy Chafets                     0   \n",
      "23452                              Jan R.                     0   \n",
      "204018                           CAROLINA                     0   \n",
      "87573                         Inflatabill                     0   \n",
      "98096                                Joan                     0   \n",
      "242532                     Elisa M. Sauer                     0   \n",
      "56400                              Nuknuk                     0   \n",
      "\n",
      "        HelpfulnessDenominator     Score        Time  \\\n",
      "9023                         0  positive  1114905600   \n",
      "51                          19  negative  1126137600   \n",
      "3884                        12  negative  1127433600   \n",
      "12264                        4  positive  1127606400   \n",
      "51113                        2  positive  1167955200   \n",
      "31621                        0  positive  1168300800   \n",
      "14367                       11  positive  1170028800   \n",
      "47456                        6  positive  1174262400   \n",
      "43469                        3  positive  1175212800   \n",
      "195209                       3  positive  1178928000   \n",
      "5582                         9  negative  1182988800   \n",
      "223108                       7  positive  1183593600   \n",
      "95646                        1  positive  1185062400   \n",
      "164268                       5  positive  1185148800   \n",
      "149578                       0  positive  1193011200   \n",
      "19007                        0  positive  1193616000   \n",
      "151852                       1  positive  1195171200   \n",
      "4013                         7  negative  1196380800   \n",
      "14156                        5  negative  1196985600   \n",
      "16905                        1  negative  1197849600   \n",
      "2848                         0  negative  1199577600   \n",
      "33650                        0  positive  1202428800   \n",
      "104401                      13  positive  1204329600   \n",
      "8210                         3  negative  1207958400   \n",
      "8768                         7  negative  1208822400   \n",
      "54480                        2  positive  1210032000   \n",
      "98502                        0  positive  1210636800   \n",
      "115252                       1  positive  1211500800   \n",
      "14101                        2  negative  1213488000   \n",
      "142400                       0  positive  1216080000   \n",
      "...                        ...       ...         ...   \n",
      "40697                        0  positive  1346803200   \n",
      "41482                        0  negative  1346889600   \n",
      "31168                        2  negative  1346976000   \n",
      "23770                        1  negative  1347148800   \n",
      "31236                        2  negative  1347580800   \n",
      "17340                        0  positive  1347580800   \n",
      "44731                        2  negative  1347580800   \n",
      "36306                        0  negative  1347667200   \n",
      "45818                        1  negative  1347840000   \n",
      "40519                        0  negative  1348444800   \n",
      "246245                       0  positive  1348444800   \n",
      "292001                       0  positive  1348531200   \n",
      "24723                        0  negative  1348531200   \n",
      "40195                        1  negative  1348617600   \n",
      "35388                        0  negative  1348704000   \n",
      "1867                         0  negative  1348790400   \n",
      "22314                        0  negative  1348963200   \n",
      "36113                        0  negative  1349222400   \n",
      "52688                        0  negative  1349481600   \n",
      "296057                       0  positive  1349568000   \n",
      "46318                        0  negative  1349740800   \n",
      "204247                       0  positive  1349913600   \n",
      "247440                       0  positive  1350000000   \n",
      "155503                       0  positive  1350086400   \n",
      "23452                        1  negative  1350604800   \n",
      "204018                       0  positive  1350777600   \n",
      "87573                        0  positive  1350950400   \n",
      "98096                        0  positive  1351036800   \n",
      "242532                       0  positive  1351036800   \n",
      "56400                        0  negative  1351123200   \n",
      "\n",
      "                                                  Summary  \\\n",
      "9023           Finally some flavored coffee for my senseo   \n",
      "51                                          Not very good   \n",
      "3884           FOOJOY LUNGCHING...I MISSED THE \"JOY\" PART   \n",
      "12264                      Best Cookies Ever!!!!!!!!!!!!!   \n",
      "51113                                             Amazing   \n",
      "31621                                   This tea is tops.   \n",
      "14367                                     Excellent Value   \n",
      "47456                                 Great for Breakfast   \n",
      "43469                           Hard to find Bisquick mix   \n",
      "195209                             My dogs love Marrobone   \n",
      "5582                 This is junk food - don't be fooled.   \n",
      "223108                         We love this dog food.....   \n",
      "95646                                         Special Tea   \n",
      "164268                     Raisins the way they should be   \n",
      "149578                    Good tasting flavored olive oil   \n",
      "19007                                     Retriever Rolls   \n",
      "151852           The best black licorice I've ever eaten!   \n",
      "4013               Too many mushrooms not enough truffles   \n",
      "14156                                                Hmmm   \n",
      "16905                                    not the greatest   \n",
      "2848    Cat doesnt like, and he's not particuliar at all.   \n",
      "33650                  Great bread for a gluten free diet   \n",
      "104401                                   Go for the burn!   \n",
      "8210            yuk! can I return the rest  for a refund?   \n",
      "8768                                      NOT GLUTEN FREE   \n",
      "54480              Something magical about this seasoning   \n",
      "98502              I like them enough to mail order them.   \n",
      "115252                                        Great taste   \n",
      "14101                            Cheaper, But Not As Good   \n",
      "142400         Makes a GREAT Breakfast or lunch or dinner   \n",
      "...                                                   ...   \n",
      "40697                                Husband loves these!   \n",
      "41482                                          Misleading   \n",
      "31168                        Why did they change this????   \n",
      "23770                          mediocre taste, expensive.   \n",
      "31236                                          Price JUMP   \n",
      "17340                                            The Best   \n",
      "44731                             Misleading the consumer   \n",
      "36306                 doesn't taste at all like it should   \n",
      "45818                           Tasted like the metal can   \n",
      "40519                            What a complete let down   \n",
      "246245                            Just the right flavors!   \n",
      "292001                                       great coffee   \n",
      "24723                                               Yuck!   \n",
      "40195            Meh.  Not that impressed. Kind of lousy.   \n",
      "35388                                             10 DAYS   \n",
      "1867          Terrible. Got no use out of the entire bag.   \n",
      "22314                        Cheaper at local stores. $15   \n",
      "36113      Made my dog throw up immediately after eating.   \n",
      "52688                                       sick as a dog   \n",
      "296057                              This bar is great!!!!   \n",
      "46318                                    Defective k-cups   \n",
      "204247                          Great coffee, good price.   \n",
      "247440                                   YUMMY and Fresh!   \n",
      "155503                                          good gift   \n",
      "23452                                 Caterpillar control   \n",
      "204018                                            5 stars   \n",
      "87573                                                Yum!   \n",
      "98096                        Pockets are Perfect for Pets   \n",
      "242532                                          Love It!!   \n",
      "56400                                Uncomfortably greasy   \n",
      "\n",
      "                                                     Text  \\\n",
      "9023    The hazelnut flavor is a little on the light s...   \n",
      "51      Debbie Lee Wesserman claims that \"the casting ...   \n",
      "3884    I thought that I would try out this product, s...   \n",
      "12264   These cookies are sooooooo good! I discovered ...   \n",
      "51113   I bought these for my daughers bday party.  Bu...   \n",
      "31621   This is one of my favorite teas.  The double d...   \n",
      "14367   I make my own coffee flavoring syrup to save m...   \n",
      "47456   According to the hype on the bag as well as th...   \n",
      "43469   I was pleased to be able to order this Bisquic...   \n",
      "195209  Nothing else gets my dogs as excited as a Marr...   \n",
      "5582    Another reason not to buy this (from Newdsay):...   \n",
      "223108  We are well into our second month of feeding o...   \n",
      "95646   This is one of my favourite teas now that I've...   \n",
      "164268  The other reviews have it spot on, these are r...   \n",
      "149578  I ordered these little bottles as party favors...   \n",
      "19007   The company is great, they are very prompt wit...   \n",
      "151852  My dad found these in Canada and we were havin...   \n",
      "4013    Product quality is average.  Mfg. has added mu...   \n",
      "14156   This was a dry, bland, not very sweet product ...   \n",
      "16905   it definitely is not the best cup of chocolate...   \n",
      "2848    Could be my cat, but too hard for him to chew,...   \n",
      "33650   My son is on a gluten free diet and he has had...   \n",
      "104401  You are probably asking, \"Why would you review...   \n",
      "8210    This gravy mix tastes terrible!, and the powde...   \n",
      "8768    This comes up on a gluten free search, but thi...   \n",
      "54480   I used to get this from local grocery stores. ...   \n",
      "98502   With 11 grams of protein and five grams of fib...   \n",
      "115252  Love the taste not to hot but a little tangy. ...   \n",
      "14101   I purchased this bottle of oil to try somethin...   \n",
      "142400  What can you really say about a cereal?  This ...   \n",
      "...                                                   ...   \n",
      "40697   My husband loves LOVES these.  He thinks the s...   \n",
      "41482   Beware -- This is a bulk food item. These are ...   \n",
      "31168   I just called Kellogg and told them how disapp...   \n",
      "23770   Grocery stores' regular potato chips taste far...   \n",
      "31236   I have been a Cheerios consumer for the full 2...   \n",
      "17340   I love this sauce.  I got some when I was in D...   \n",
      "44731   I am always looking for new cereal products.  ...   \n",
      "36306   I am not normally one to review things.  I had...   \n",
      "45818   I had purchased this product at Whole Foods af...   \n",
      "40519   I will start by saying I thought I was getting...   \n",
      "246245  I got the variety pack of waters, and really l...   \n",
      "292001  I was a little worried due to a few bad rewiew...   \n",
      "24723   We got this flavor because it was A)on sale an...   \n",
      "40195   I mean, yeah, it's coffee.  True dat.  But it'...   \n",
      "35388   I LOVE THIS COFFEE, MUCH BETTER THAN THE REGUL...   \n",
      "1867    When I received the bag about 40 percent of th...   \n",
      "22314   This package that is sold on amazon for $20 is...   \n",
      "36113   Made my dog throw up immediately after eating....   \n",
      "52688   no stars-my dog got so sick from these and aft...   \n",
      "296057  I just had one of these bars today and I got t...   \n",
      "46318   I have purchased hundreds of k-cups over the p...   \n",
      "204247  I purchased Coffee Bean Direct Breakfast Blend...   \n",
      "247440  I made shark kabobs for my son's Shark birthda...   \n",
      "155503  Bought this for a frequent house guest.  It is...   \n",
      "23452   I found this product very difficult to use.  D...   \n",
      "204018  I LOVE THIS COFFEE. IT THE PERFECT BLEND FOR M...   \n",
      "87573   I was first introduced to the Rub with Love pr...   \n",
      "98096   If need to give your dog medicine these pill p...   \n",
      "242532  Ocean Spray On the Go Sugar Free Drink Mix  ar...   \n",
      "56400   Greasy. Plain and simple. It does relieve itch...   \n",
      "\n",
      "                                              CleanedText  \n",
      "9023    b'hazelnut flavor littl light side that way li...  \n",
      "51      b'debbi lee wesserman claim cast movi perfect ...  \n",
      "3884    b'thought would tri product sinc ive tri numbe...  \n",
      "12264   b'cooki sooooooo good discov flight europ imme...  \n",
      "51113   b'bought daugher bday parti husband want tri f...  \n",
      "31621   b'one favorit tea doubl dose bergamot give ear...  \n",
      "14367   b'make coffe flavor syrup save money howev exp...  \n",
      "47456   b'accord hype bag well nutrit inform whole gra...  \n",
      "43469   b'pleas abl order bisquick mix store area long...  \n",
      "195209  b'noth els get dog excit marrobon treat keep s...  \n",
      "5582    b'anoth reason buy newdsay sea cliff food comp...  \n",
      "223108  b'well second month feed pound black lab excel...  \n",
      "95646   b'one favourit tea ive found absolut delici bl...  \n",
      "164268     b'review spot realli good especi first unseal'  \n",
      "149578  b'order littl bottl parti favor think work gre...  \n",
      "19007   b'compani great prompt order problem might dog...  \n",
      "151852  b'dad found canada hard time find onlin suppli...  \n",
      "4013    b'product qualiti averag mfg ad mushroom butte...  \n",
      "14156   b'dri bland sweet product well blend love halv...  \n",
      "16905   b'definit best cup chocol seem wateri alway ad...  \n",
      "2848    b'could cat hard chew doesnt like tast product...  \n",
      "33650   b'son gluten free diet realli hard time withou...  \n",
      "104401  b'probabl ask would review diet coke damn soda...  \n",
      "8210    b'gravi mix tast terribl powder onion aftertas...  \n",
      "8768    b'come gluten free search gluten free soy sauc...  \n",
      "54480   b'use get local groceri store recent like revi...  \n",
      "98502   b'gram protein five gram fiber find bar good d...  \n",
      "115252  b'love tast hot littl tangi price good realli ...  \n",
      "14101   b'purchas bottl oil tri someth differ mustapha...  \n",
      "142400  b'realli say cereal stuff fantast pricey side ...  \n",
      "...                                                   ...  \n",
      "40697   b'husband love love think sardin delici mustar...  \n",
      "41482   b'bewar bulk food item individu wrap shown pic...  \n",
      "31168   b'call kellogg told disappoint new formula spe...  \n",
      "23770   b'groceri store regular potato chip tast far b...  \n",
      "31236   b'cheerio consum full year life ive seen price...  \n",
      "17340   b'love sauc got dalla last year cousin sent be...  \n",
      "44731   b'alway look new cereal product usual stay awa...  \n",
      "36306   b'normal one review thing italian dark mfg pre...  \n",
      "45818   b'purchas product whole food anoth custom high...  \n",
      "40519   b'start say thought get someth good decid spic...  \n",
      "246245  b'got varieti pack water realli like refresh f...  \n",
      "292001  b'littl worri due bad rewiew coff great smell ...  \n",
      "24723   b'got flavor sale tasti right wrong wont much ...  \n",
      "40195   b'mean yeah coffe true dat good think better e...  \n",
      "35388   b'love coffe much better regular roast local m...  \n",
      "1867    b'receiv bag percent bead alreadi crush power ...  \n",
      "22314   b'packag sold amazon less big box store one an...  \n",
      "36113   b'made dog throw immedi eat tri bison freez dr...  \n",
      "52688   b'dog got sick read ill even death dog ate gla...  \n",
      "296057  b'one bar today got tell good kind like almond...  \n",
      "46318   b'purchas hundr past four year never experienc...  \n",
      "204247  b'purchas coffe bean direct breakfast blend ba...  \n",
      "247440  b'made shark kabob son shark birthday parti cu...  \n",
      "155503  b'bought frequent hous guest conveni bottl rat...  \n",
      "23452   b'found product difficult use dont think would...  \n",
      "204018  b'love coffe perfect blend arriv fresh love co...  \n",
      "87573   b'first introduc rub love product salmon rub o...  \n",
      "98096   b'need give dog medicin pill pocket best dog l...  \n",
      "242532  b'ocean spray sugar free drink mix great use d...  \n",
      "56400   b'greasi plain simpl reliev itchi scalp negat ...  \n",
      "\n",
      "[400 rows x 12 columns]>\n",
      "(400, 12)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "#using the preprocess Sqlite Table to read the  data\n",
    "con = sqlite3.connect('./amazon-fine-food-reviews/finalsqlite')\n",
    "\n",
    "#Filtering only positive review\n",
    "positive_review = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM Reviews Where Score == 'positive'\n",
    "\"\"\", con)\n",
    "\n",
    "#Extracting 2000 Positive review Randomly\n",
    "positive_smaller_review_set = positive_review.sample(200)\n",
    "print(positive_smaller_review_set.shape)\n",
    "\n",
    "#Filtering only negative review\n",
    "negative_review = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM Reviews Where Score == 'negative'\n",
    "\"\"\", con)\n",
    "\n",
    "#Extracing 2000 random negative review\n",
    "negative_smaller_review_set = negative_review.sample(200)\n",
    "print(negative_smaller_review_set.shape)\n",
    "\n",
    "#Concanating Negative and Positive review into one dataframe\n",
    "frames = [positive_smaller_review_set, negative_smaller_review_set]\n",
    "final = pd.concat(frames)\n",
    "\n",
    "#Sort the dataframe data into the increasing Time order\n",
    "final = final.sort_values(by=['Time'])\n",
    "print(final.head)\n",
    "print(final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag OF word(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector of Preprocess review(text) after BOW(unigram) (400, 2806)\n"
     ]
    }
   ],
   "source": [
    "#BOW of preprocess text\n",
    "count_vect = CountVectorizer()\n",
    "final_counts_preprocess_text = count_vect.fit_transform(final['CleanedText'].values)\n",
    "\n",
    "print(\"Shape of vector of Preprocess review(text) after BOW(unigram)\",final_counts_preprocess_text.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standariztion Of Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DANAV\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standarization OF review text\n",
    "standarized_data = StandardScaler().fit_transform(final_counts_preprocess_text.toarray()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2806)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "# create design matrix X and target vector y\n",
    "\n",
    "X = np.array(standarized_data[:,:])  \n",
    "y = np.array(final['Score'].values)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# Calculating the train and test size and dividing the data into train and test chunks into the 70 - 30 ratio\n",
    "train_size = math.floor(X.shape[0] * 0.7)\n",
    "\n",
    "#split the data set into train and test\n",
    "X_train = X[: train_size ,:]\n",
    "X_test  = X[train_size : , :]  \n",
    "y_train = y[: train_size ]\n",
    "y_test =  y[train_size : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Serach On Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DANAV\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1030: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if pos_label not in present_labels:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['negative', 'positive'], dtype='<U8')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e7e93d4e8200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# print(model.score(X_test, y_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m         \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m             \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[1;32m--> 108\u001b[1;33m                                                  **self._kwargs)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[1;32m-> 1036\u001b[1;33m                                      (pos_label, present_labels))\n\u001b[0m\u001b[0;32m   1037\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['negative', 'positive'], dtype='<U8')"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tuned_parameters =[{'C' : [10 **-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.best_estimator_)\n",
    "# print(model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector of Preprocess review(text) after Tf-Idf (100, 7274)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf of preprocess text\n",
    "tf_idf_vect  = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf_preprocess_text =  tf_idf_vect.fit_transform(final['Text'].values)\n",
    "\n",
    "#Shape of  vectors\n",
    "print(\"Shape of vector of Preprocess review(text) after Tf-Idf\",final_tf_idf_preprocess_text.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Standariztion Of Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standarization OF review text\n",
    "standarized_data = StandardScaler().fit_transform(final_tf_idf_preprocess_text.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn on TF-IDF vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Tf-Idf using Brute Force approach for k = 21 is 53.333333%\n",
      "kd_tree\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Tf-Idf using K_D tree approach for k = 21 is 53.333333%\n"
     ]
    }
   ],
   "source": [
    "# Using knn_accuracy Function finding optimal k and accuracy on that optimal k\n",
    "\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'brute')\n",
    "print('\\nThe accuracy of the knn classifier on Tf-Idf using Brute Force approach for k = %d is %f%%' % (optimal_k, acc))\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'kd_tree')\n",
    "print('\\nThe accuracy of the knn classifier on Tf-Idf using K_D tree approach for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition oF CleanHtml and CleanPunc for Preprocessing the reviw text\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "\n",
    "# Train your own Word2Vec model using your own text corpus\n",
    "\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=1,size=50, workers=4)\n",
    "                                 \n",
    "Avg_sent_vectors = []\n",
    "for sent in list_of_sent:\n",
    "    sent_vect = np.zeros(50)\n",
    "    count = 0\n",
    "    for word in sent:\n",
    "        try :\n",
    "            sent_vect += w2v_model.wv[word]\n",
    "            count = count + 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    sent_vect = sent_vect / count\n",
    "    Avg_sent_vectors.append(sent_vect)\n",
    "     \n",
    "#Standarization Of Avg Word2Vec vector\n",
    "standardized_data = StandardScaler().fit_transform(Avg_sent_vectors)\n",
    "print(standardized_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn on Average Word2Vec vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Word2vec using Brute Force approach for k = 21 is 53.333333%\n",
      "kd_tree\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Word2vec using K_D tree approach for k = 21 is 53.333333%\n"
     ]
    }
   ],
   "source": [
    "# Using knn_accuracy Function finding optimal k and accuracy on that optimal k\n",
    "\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'brute')\n",
    "print('\\nThe accuracy of the knn classifier on Word2vec using Brute Force approach for k = %d is %f%%' % (optimal_k, acc))\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'kd_tree')\n",
    "print('\\nThe accuracy of the knn classifier on Word2vec using K_D tree approach for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DANAV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_feat = tf_idf_vect.get_feature_names()\n",
    "tfidf_sent_vect=[]\n",
    "row= 0;\n",
    "for sent in list_of_sent:\n",
    "    sent_vec = np.zeros(50)\n",
    "    weight_sum = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            if((word in  w2v_model.wv.vocab) and (word in tf_idf_feat)):\n",
    "                w_vec = w2v_model.wv[word]\n",
    "                tf_idf_vec = final_tf_idf[row,tf_idf_feat.index(word)]\n",
    "                sent_vec = sent_vec + (w_vec*tf_idf_vec)\n",
    "                weight_sum = weight_sum + tf_idf_vec\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec = sent_vec/weight_sum\n",
    "    tfidf_sent_vect.append(sent_vec)\n",
    "    row= row+1\n",
    "    \n",
    "# Removing NAN values    \n",
    "tfidf_sent_vect_values = np.nan_to_num(tfidf_sent_vect)\n",
    "\n",
    "#Standarization Of Tf-Idf Word2Vec Vector\n",
    "standardized_data = StandardScaler().fit_transform(tfidf_sent_vect_values)\n",
    "print(standardized_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn on Tf-Idf Word2Vec vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Tf-Idf Word2vec using Brute Force approach for k = 21 is 53.333333%\n",
      "kd_tree\n",
      "[0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5267857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.5142857142857142, 0.4708333333333333, 0.5, 0.5125, 0.4976190476190475, 0.4976190476190476]\n",
      "\n",
      "The optimal number of neighbors is 21.\n",
      "\n",
      "The accuracy of the knn classifier on Tf-Idf Word2vec using K_D tree approach for k = 21 is 53.333333%\n"
     ]
    }
   ],
   "source": [
    "# Using knn_accuracy Function finding optimal k and accuracy on that optimal k\n",
    "\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'brute')\n",
    "print('\\nThe accuracy of the knn classifier on Tf-Idf Word2vec using Brute Force approach for k = %d is %f%%' % (optimal_k, acc))\n",
    "optimal_k, acc =  knn_accuracy(standarized_data , algorithms = 'kd_tree')\n",
    "print('\\nThe accuracy of the knn classifier on Tf-Idf Word2vec using K_D tree approach for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
